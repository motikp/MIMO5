{"cells": [{"source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='e20ab378-6d92-49b9-a58b-2510f71f0396', project_access_token='p-1f59b98d29e73a662229f2aaf14e47597c091310')\n", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"metadata": {}, "cell_type": "markdown", "source": "# Explore the TensorFlow Speech Commands Dataset\n\nThis notebook relates to the **TensorFlow Speech Commands Dataset**. TensorFlow Speech Command dataset is a set of one-second `.wav` audio files, each containing a single spoken English word. These words are from a small set of commands, and are spoken by a variety of different speakers. It was designed for limited vocabulary speech recognition tasks. This dataset can be obtained for free from the IBM Developer [Data Asset Exchange](https://developer.ibm.com/exchanges/data/all/speech-commands/).\n\nIn this notebook, we will download the dataset archive from cloud storage, extract it, explore the dataset and import audio samples into our Watson Studio project.\n\n### Table of Contents:\n* [0. Prerequisites](#cell0)\n* [1. Download and Extract Dataset Archive](#cell1)\n* [2. Inspect audio samples](#cell2)\n* [3. Add Dataset Files to Watson Studio Project](#cell3)\n* [Authors](#authors)\n\n\n<a id=\"cell0\"></a>\n### 0. Prerequisites\n\nBefore you run this notebook complete the following steps:\n- Insert a project token\n- Import required packages\n\n#### Insert a project token\n\nWhen you import this project from the Watson Studio Gallery, a token should be automatically generated and inserted at the top of this notebook as a code cell such as the one below:\n\n```python\n# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='YOUR_PROJECT_ID', project_access_token='YOUR_PROJECT_TOKEN')\npc = project.project_context\n```\n\nIf you do not see the cell above, follow these steps to enable the notebook to access the dataset from the project's resources:\n\n* Click on `More -> Insert project token` in the top-right menu section\n\n![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n\n* This should insert a cell at the top of this notebook similar to the example given above.\n\n  > If an error is displayed indicating that no project token is defined, follow [these instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/token.html?audience=wdp&context=data).\n\n* Run the newly inserted cell before proceeding with the notebook execution below\n\n#### Import required packages"}, {"metadata": {}, "cell_type": "code", "source": "import requests\nimport os\nimport tarfile\nfrom pathlib import Path\nfrom urllib.parse import urlparse\nimport glob\nimport IPython.display as ipd\nfrom IPython.display import Markdown, display\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\ndef printmd(string):\n    display(Markdown(string))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell1\"></a>\n### 1. Download and extract the dataset archive\n\nFirst, we download the TensorFlow Speech Commands data set archive from the Data Asset Exchange cloud storage and extract the data files."}, {"metadata": {}, "cell_type": "code", "source": "# Dataset archive location on public cloud storage\nfname = 'tensorflow-speech-commands.tar.gz'\nurl = 'https://dax-cdn.cdn.appdomain.cloud/dax-tensorflow-speech-commands/1.0.1/'\ndata_path = 'TensorFlow-Speech-Commands'\nfilenames = ['on/0a7c2a8d_nohash_0.wav', 'off/0ab3b47d_nohash_0.wav', 'up/0a7c2a8d_nohash_0.wav', 'bird/0a7c2a8d_nohash_0.wav', 'bird/0c2ca723_nohash_1.wav',\n             'sheila/00f0204f_nohash_1.wav', 'cat/0ab3b47d_nohash_0.wav', 'dog/0b09edd3_nohash_1.wav', 'right/0a7c2a8d_nohash_0.wav',\n             'bird/0b77ee66_nohash_0.wav', 'bird/0eb48e10_nohash_1.wav', 'bird/0fa1e7a9_nohash_0.wav', 'bird/1d919a90_nohash_2.wav', 'zero/0c40e715_nohash_0.wav']\ndownload_link = url + fname\nr = requests.get(download_link)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Download and extract the dataset archive. "}, {"metadata": {}, "cell_type": "code", "source": "print('Downloading dataset archive {} ...'.format(download_link))\n\nr = requests.get(download_link)\n\nif r.status_code != 200:\n    print('Error. Dataset archive download failed.')\nelse:\n    # save the downloaded archive\n    print('Saving downloaded archive as {} ...'.format(fname))\n    with open(fname, 'wb') as downloaded_file:\n        downloaded_file.write(r.content)\n    \n    if tarfile.is_tarfile(fname):\n        # extract the downloaded archive\n        print('Extracting downloaded archive ...')\n        with tarfile.open(fname, 'r') as tar:\n            tar.extractall()\n        print('Removing downloaded archive ...')\n        Path(fname).unlink()\n        print('Done.')\n    else:\n        print('Error. The downloaded file is not a valid TAR archive.')\n    ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell3\"></a>\n### 2. Inspect audio samples\n\nIn this section, we would like to inspect the TensorFlow Speech Command dataset after download and extraction.\n\nIn this dataset, there are 31 audio folders. 20 of the words are core words, while 10 words are auxiliary words that could act as tests for algorithms in ignoring speeches that do not contain triggers. Included along with the 30 words is a collection of background noise audio files. The audio clips were originally collected by Google, and recorded by volunteers in uncontrolled locations around the world. "}, {"metadata": {}, "cell_type": "code", "source": "# Save audio sample labels\nlabels  = [name for name in os.listdir(data_path) if name not in ['info.txt', 'LICENSE', 'validation_list.txt', 'README.md', 'testing_list.txt'] if os.path.isdir(data_path)]\n# Get the folder list\nfolders = glob.glob(data_path + '/*')\n# Number of samples in each category of audio clip\nrecordings = []\nfor i in folders:\n    if os.path.isdir(i):\n        samples = [f for f in os.listdir(i) if f.endswith('.wav') ]\n        recordings.append(len(samples))\n        \nprintmd('**Core words and number of samples from audio samples:**')\nprint([(labels[i], recordings[i]) for i in range(0, len(labels))]) ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The list above is hard to read or compare the number between different audio sample folders. Let's visualize the audio sample distribution."}, {"metadata": {}, "cell_type": "code", "source": "# Plot\ndata = [go.Histogram(x=folders, y=recordings, text='pop')]\ntrace = go.Bar(\n    x=labels,\n    y=recordings,\n    marker=dict(color = recordings),\n    text = recordings,\n    textposition='outside'\n)\nlayout = go.Layout(\n    title='Number of recordings in given label',\n    xaxis = dict(title='Words'),\n    yaxis = dict(title='Number of recordings')\n)\npy.iplot(go.Figure(data=[trace], layout=layout))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Play audio - sample 1\nprintmd('**Core word** - ' + filenames[0][0:2] )\nprintmd('**Speaker** - ' + filenames[0][3:])\nipd.Audio(os.path.join(data_path, filenames[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Play audio - sample 2\nprintmd('**Core word** - ' + filenames[1][0:3] )\nprintmd('**Speaker** - ' + filenames[1][4:])\nipd.Audio(os.path.join(data_path, filenames[1]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Play audio - sample 3\nprintmd('**Core word** - ' + filenames[2][0:2] )\nprintmd('**Speaker** - ' + filenames[2][3:])\nipd.Audio(os.path.join(data_path, filenames[2]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Play audio - sample 4\nprintmd('**Auxillary word** - ' + filenames[3][0:4] )\nprintmd('**Speaker** - ' + filenames[3][5:])\nipd.Audio(os.path.join(data_path, filenames[3]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Play audio - sample 5, another bird sound file\nprintmd('**Auxillary word** - ' + filenames[3][0:4] )\nprintmd('**Speaker** - ' + filenames[3][6:])\nipd.Audio(os.path.join(data_path, filenames[4]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cell3\"></a>\n### 3. Add Dataset Files to Watson Studio Project\n\nNext, we add the extracted data files to the Watson Studio project to make them available to the other notebooks."}, {"metadata": {}, "cell_type": "code", "source": "# Verify that the extracted artifacts are located in the expected location\nif not Path(data_path).exists():\n    print('Error. The extracted data files are not located in the {} directory.'.format(data_path_.name))\nelse:\n    # Save extracted data file(s) as project assets\n    data_asset_count = 0\n    for file in filenames:\n        # save data file as a data asset in the project\n        with open(data_path + '/' + file, 'rb') as f:\n            file = file.replace('/', '_')\n            print(file)\n            file = file.split('.')\n            print('Saving as {}.wav to project data asset ...'.format(file[0]))\n            project.save_data(file[0] + '.wav', f.read(), set_project_asset=True, overwrite=True)\n        data_asset_count = data_asset_count + 1\n        # remove the file to free up space\n    print('Number of added data assets: {} '.format(data_asset_count))\n    print('You are ready to run the other notebooks.')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Next steps\n* Close this notebook.\n* Open the `Part 2 - Dataset Visualization` notebook to learn more about the data."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"authors\"></a> \n### Authors\n\nThis notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n<br><br>\n\nCopyright \u00a9 2020-2021 IBM. This notebook and its source code are released under the terms of the MIT License.\n<br><br>\n<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}